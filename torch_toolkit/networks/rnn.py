"""Various recurrent layers and utilitiyes"""

__all__ = ['break_grad', 'mask_state', 'update_state_with_index', 'ResetGRU', 'NormGRUCell', 'update_state_with_mask']
from typing import Optional, Tuple, Dict

import torch
import torch as th
import torch.nn as nn
from ..typing import Tensor, TensorDict, OptionalTensor
from .init import layer_init, ORTHOGONAL_INIT_VALUES
from .normalization import RMSNorm


def break_grad(x: Tensor) -> Tensor:
    """Detach and reattach gradient (e.g., across batch boundaries)

    Args:
        x: Input tensor
    Returns:
        Tensor without previous gradient history
    """
    return x.detach_().requires_grad_()


def mask_state(state_original: Tensor, reset: Tensor, initial_state: Tensor) -> Tensor:
    """Replace state with initial state where reset

    Args:
        state_original: [Bxh] incoming state
        reset: [B] float or bool tensor (1 where reset)
        initial_state: [B/1xh] initial state to use where we reset
    Returns:
        modified state
    """
    rs = reset.float().unsqueeze(-1)  # Convert to float, unqueeze batch dim
    return state_original * (1. - rs) + initial_state.expand_as(state_original) * rs


def update_state_with_mask(state_original: Tensor, update: Tensor, new_state: Tensor) -> Tensor:
    """Update state with new state where updating. Allows us to update different elements of state batch at varying times

    Args:
        state_original: [Bxh] incoming state
        update: [B] mask which is >0 where we're updating state on this timestep
        new_state: [<B] new state as generated by gru(x[update], state_original[update])
    Returns:
        new_state. Uses original state where we aren't updating, uses new state where we are. Preserves gradient
    """
    s = th.zeros_like(state_original)
    s = th.masked_scatter(s, (update > 0).unsqueeze(-1), new_state)
    return mask_state(state_original, update.float(), s)


def update_state_with_index(state: Tensor, tidx: Tensor, ntidx: Tensor, idx_state: Tensor) -> Tensor:
    """Update state at idx with idx_state, otherwise return state

    Args:
        state: Original state
        tidx: bool or long tensor with indices where we update state
        ntidx: bool or long tensor with indices where we don't update state
        idx_state: [ntidx.shape[0]xh] Updated state
    Returns:
        state updated where it needs to be
    """
    s = th.zeros_like(state)
    s[tidx] = idx_state
    s[ntidx] = state[ntidx]
    return s


class SequentialPassState(nn.Sequential):
    """Sequential Module that takes additional input that it ignores"""
    def forward(self, x, state: Optional[Tensor] = None) -> Tuple[Tensor, Optional[Tensor]]:
        for module in self:
            x = module(x)
        return x, state


class SequentialStartState(nn.Sequential):
    """Sequential module that takes additional input only relevant to first module"""
    def forward(self, x, state: Optional[Tensor] = None) -> Tuple[Tensor, Optional[Tensor]]:
        for i, module in enumerate(self):
            if i == 0: x, state = module(x, state)
            else: x = module(x)
        return x, state


class ResetCore(nn.Module):
    """Clone of haiku's hk.ResetCore with more features

    Reset incoming state based on "should_reset" signal

    Args:
        rnn: RNN module
        learning_dim: If 0, typical zero-reset. If 1, single learnable state. If >1, multiple learnable states (i.e., per-option)
    """
    __constants__ = ['ldim', 'hidden_size']
    hidden_size: torch.jit.Final[int]
    ldim: torch.jit.Final[int]

    def __init__(self, rnn: nn.Module, learning_dim: int):
        super().__init__()
        assert learning_dim >= 0
        self.rnn = rnn
        self.hidden_size = getattr(rnn, 'hidden_size', 0)  # Recurrent modules have hidden size, others do not
        if not self.hidden_size: learning_dim = 0
        self.ldim = learning_dim
        self._initial_state = nn.Parameter(torch.zeros(self.ldim, self.hidden_size), requires_grad=bool(learning_dim))

    def forward(self, state, should_reset, reset_indices: Optional[torch.LongTensor] = None):
        """"""
        if self.ldim <= 1: return mask_state(state, should_reset, self._initial_state)
        else:
            if reset_indices is None: reset_indices = torch.zeros_like(should_reset, dtype=torch.int64)
            return mask_state(state, should_reset, self.initial_state_index(reset_indices))

    def initial_state(self, b: int = 1):
        return self._initial_state.expand(b, -1)

    def initial_state_index(self, indices: torch.LongTensor):
        return self._initial_state[indices]



class NormGRUCell(nn.RNNCellBase):
    n_preact: torch.jit.Final[bool]
    """Layer/RMS-normalized GRU as in https://arxiv.org/pdf/1607.06450.pdf

    https://github.com/pytorch/pytorch/issues/12482#issuecomment-440485163"""
    def __init__(self, input_size, hidden_size, bias=True, n_preact=True, norm_type: str = 'rms'):
        super().__init__(input_size, hidden_size, bias, num_chunks=3)
        norm_cls = RMSNorm if norm_type == 'rms' else nn.LayerNorm
        self.n_preact = n_preact
        if n_preact:
            self.n_ih = norm_cls(3 * self.hidden_size)
            self.n_hh = norm_cls(3 * self.hidden_size)
        self.n_in = norm_cls(self.hidden_size)
        self.n_hn = norm_cls(self.hidden_size)

    def forward(self, input: Tensor, hx: Tensor):
        ih = input @ self.weight_ih.t() + self.bias_ih
        hh = hx @ self.weight_hh.t() + self.bias_hh
        if self.n_preact:
            ih = self.n_ih(ih)
            hh = self.n_hh(hh)

        i_r, i_z, i_n = ih.chunk(3, dim=1)
        h_r, h_z, h_n = hh.chunk(3, dim=1)
        i_n = self.n_in(i_n)
        h_n = self.n_hn(h_n)

        r = th.sigmoid(i_r + h_r)
        z = th.sigmoid(i_z + h_z)
        n = th.tanh(i_n + r * h_n)
        h = (1 - z) * n + z * hx
        return h


class ResetGRU(nn.Module):
    """GRU that automatically resets state according to dones. Optional learnable state. Optional sometimes updating

    Args:
        input_size: Size of incoming tensor
        hidden_size: Size of GRU
        learnable_state: Whether to do a learnable initial state or just reset to 0s. If >1, multiple learnable states
        layer_norm: Whether to use a layer normalized GRUCell
        variable_update: If False (default), assume we update all elements of state every time this is called. If True, take update_mask parameter into account
    """
    def __init__(self, input_size: int, hidden_size: int, learnable_state: int = 0, layer_norm: bool = False, variable_update: bool = False):
        super().__init__()
        gru_cls = NormGRUCell if layer_norm else nn.GRUCell
        self.core = layer_init(gru_cls(input_size, hidden_size), ORTHOGONAL_INIT_VALUES['sigmoid'])
        init_state = th.zeros(1, hidden_size)
        if learnable_state:
            init_state = th.tile(init_state, (learnable_state, 1))
            self.register_parameter('init_state', nn.Parameter(init_state))
        else: self.register_buffer('init_state', init_state)
        self.variable_update = variable_update

    def _update_at_mask(self, x, state, update_mask):
        """Update state at mask. Saves computation by only computing new states for updating indices"""
        s = th.zeros_like(state)
        f_idx = self.core(x[update_mask], state[update_mask])
        s[update_mask] = f_idx
        return mask_state(state, update_mask, s)

    def _step_one(self, x: Tensor, state: Tensor, reset: Optional[Tensor] = None, idx: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Single step"""
        if reset is not None:
            state = mask_state(state, reset, self.init_state[idx])
        f = self.core(x, state)
        return f, f.clone()

    def _unroll(self, x: Tensor, state: Tensor, reset: Optional[Tensor] = None, idx: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Multi-step"""
        T, B = x.shape[:2]
        states = []
        if reset is not None and idx is not None:
            for t in range(T):
                state = mask_state(state, reset[t], self.init_state[idx[t]])
                states.append(self.core(x[t], state))
                state = states[-1]
        else:
            for t in range(T):
                states.append(self.core(x[t], state))
                state = states[-1]
        return th.stack(states, 0), state


    def forward(self, x: Tensor, state: Optional[Tensor] = None,
                reset: Optional[Tensor] = None, idx: Optional[Tensor] = None,
                # update_mask: Optional[th.BoolTensor] = None
                ) -> Tuple[Tensor, Tensor]:
        """Forward pass

        Args:
            x: Tensor input. Size is [T?xBxi].
            state: Tensor input for incoming state. Size is [Bxh]. If None, use initial state
            reset: Tensor input telling where to reset to initial state. Size if [T?xB]. If None, assume no resets.
            idx: Tensor input telling which initial state to use (if resetting). If None, assume first index
            # update_mask: Tensor input telling where state should actually be updated. Where not updating, use old state. If None, assume all update
        Returns:
            (output [T?xBxi], last state[Bxi]) tuple
        """
        if idx is None: idx = th.zeros(x.shape[:-1], device=x.device, dtype=th.int64)
        if state is None: state = self.init_state[0].unsqueeze(0).expand(x.shape[-2], -1)
        if reset is None: reset = th.zeros_like(idx, dtype=th.float32)
        if x.dim() == 2:
            return self._step_one(x, state, reset, idx)
        else:
            return self._unroll(x, state, reset, idx)

