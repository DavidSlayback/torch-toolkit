__all__ = ['break_grad', 'mask_state', 'update_state_with_index', 'ResetGRU', 'LayerNormGRUCell', 'update_state_with_mask']
from typing import Optional, Tuple, Dict

import torch as th
import torch.nn as nn
Tensor = th.Tensor
TensorDict = Dict[str, Tensor]
from .init import layer_init, ORTHOGONAL_INIT_VALUES


def break_grad(x: Tensor) -> Tensor:
    """Detach and reattach gradient (e.g., across batch boundaries)

    Args:
        x: Input tensor
    Returns:
        Tensor without previous gradient history
    """
    return x.detach_().requires_grad_()


def mask_state(state_original: Tensor, reset: Tensor, initial_state: Tensor) -> Tensor:
    """Replace state with initial state where reset

    Args:
        state_original: [Bxh] incoming state
        reset: [B] float or bool tensor (1 where reset)
        initial_state: [B/1xh] initial state to use where we reset
    Returns:
        modified state
    """
    return state_original * (1. - reset.unsqueeze(-1)) + initial_state.expand_as(state_original) * reset.unsqueeze(-1)


def update_state_with_mask(state_original: Tensor, update: Tensor, new_state: Tensor) -> Tensor:
    """Update state with new state where updating. Allows us to update different elements of state batch at varying times

    Args:
        state_original: [Bxh] incoming state
        update: [B] mask which is >0 where we're updating state on this timestep
        new_state: [<B] new state as generated by gru(x[update], state_original[update])
    Returns:
        new_state. Uses original state where we aren't updating, uses new state where we are. Preserves gradient
    """
    s = th.zeros_like(state_original)
    s = th.masked_scatter(s, (update > 0).unsqueeze(-1), new_state)
    return mask_state(state_original, update.float(), s)


def update_state_with_index(state: Tensor, tidx: Tensor, ntidx: Tensor, idx_state: Tensor) -> Tensor:
    """Update state at idx with idx_state, otherwise return state

    Args:
        state: Original state
        tidx: bool or long tensor with indices where we update state
        ntidx: bool or long tensor with indices where we don't update state
        idx_state: [ntidx.shape[0]xh] Updated state
    Returns:
        state updated where it needs to be
    """
    s = th.zeros_like(state)
    s[tidx] = idx_state
    s[ntidx] = state[ntidx]
    return s


class LayerNormGRUCell(nn.RNNCellBase):
    """Layer-normalized GRU as in https://arxiv.org/pdf/1607.06450.pdf

    https://github.com/pytorch/pytorch/issues/12482#issuecomment-440485163"""
    def __init__(self, input_size, hidden_size, bias=True, ln_preact=True):
        super().__init__(input_size, hidden_size, bias, num_chunks=3)
        self.ln_preact = ln_preact
        if ln_preact:
            self.ln_ih = nn.LayerNorm(3 * self.hidden_size)
            self.ln_hh = nn.LayerNorm(3 * self.hidden_size)
        self.ln_in = nn.LayerNorm(self.hidden_size)
        self.ln_hn = nn.LayerNorm(self.hidden_size)

    def forward(self, input: Tensor, hx: Tensor):
        ih = input @ self.weight_ih.t() + self.bias_ih
        hh = hx @ self.weight_hh.t() + self.bias_hh
        if self.ln_preact:
            ih = self.ln_ih(ih)
            hh = self.ln_hh(hh)

        i_r, i_z, i_n = ih.chunk(3, dim=1)
        h_r, h_z, h_n = hh.chunk(3, dim=1)
        i_n = self.ln_in(i_n)
        h_n = self.ln_hn(h_n)

        r = th.sigmoid(i_r + h_r)
        z = th.sigmoid(i_z + h_z)
        n = th.tanh(i_n + r * h_n)
        h = (1 - z) * n + z * hx
        return h


class ResetGRU(nn.Module):
    """GRU that automatically resets state according to dones. Optional learnable state. Optional sometimes updating

    Args:
        input_size: Size of incoming tensor
        hidden_size: Size of GRU
        learnable_state: Whether to do a learnable initial state or just reset to 0s. If >1, multiple learnable states
        layer_norm: Whether to use a layer normalized GRUCell
        variable_update: If False (default), assume we update all elements of state every time this is called. If True, take update_mask parameter into account
    """
    def __init__(self, input_size: int, hidden_size: int, learnable_state: int = 0, layer_norm: bool = False, variable_update: bool = False):
        super().__init__()
        gru_cls = LayerNormGRUCell if layer_norm else nn.GRUCell
        self.core = layer_init(gru_cls(input_size, hidden_size), ORTHOGONAL_INIT_VALUES['sigmoid'])
        init_state = th.zeros(1, hidden_size)
        if learnable_state:
            init_state = th.tile(init_state, (learnable_state, 1))
            self.register_parameter('init_state', nn.Parameter(init_state))
        else: self.register_buffer('init_state', init_state)
        self.variable_update = variable_update

    def _update_at_mask(self, x, state, update_mask):
        """Update state at mask. Saves computation by only computing new states for updating indices"""
        s = th.zeros_like(state)
        f_idx = self.core(x[update_mask], state[update_mask])
        s[update_mask] = f_idx
        return mask_state(state, update_mask, s)

    def _step_one(self, x: Tensor, state: Tensor, reset: Optional[Tensor] = None, idx: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Single step"""
        if reset is not None:
            state = mask_state(state, reset, self.init_state[idx])
        f = self.core(x, state)
        return f, f.clone()

    def _unroll(self, x: Tensor, state: Tensor, reset: Optional[Tensor] = None, idx: Optional[Tensor] = None) -> Tuple[Tensor, Tensor]:
        """Multi-step"""
        T, B = x.shape[:2]
        states = []
        if reset is not None and idx is not None:
            for t in range(T):
                state = mask_state(state, reset[t], self.init_state[idx[t]])
                states.append(self.core(x[t], state))
                state = states[-1]
        else:
            for t in range(T):
                states.append(self.core(x[t], state))
                state = states[-1]
        return th.stack(states, 0), state


    def forward(self, x: Tensor, state: Optional[Tensor] = None,
                reset: Optional[Tensor] = None, idx: Optional[Tensor] = None,
                # update_mask: Optional[th.BoolTensor] = None
                ) -> Tuple[Tensor, Tensor]:
        """Forward pass

        Args:
            x: Tensor input. Size is [T?xBxi].
            state: Tensor input for incoming state. Size is [Bxh]. If None, use initial state
            reset: Tensor input telling where to reset to initial state. Size if [T?xB]. If None, assume no resets.
            idx: Tensor input telling which initial state to use (if resetting). If None, assume first index
            # update_mask: Tensor input telling where state should actually be updated. Where not updating, use old state. If None, assume all update
        Returns:
            (output [T?xBxi], last state[Bxi]) tuple
        """
        if idx is None: idx = th.zeros(x.shape[:-1], device=x.device, dtype=th.int64)
        if state is None: state = self.init_state[0].unsqueeze(0).expand(x.shape[-2], -1)
        if reset is None: reset = th.zeros_like(idx, dtype=th.float32)
        if x.dim() == 2:
            return self._step_one(x, state, reset, idx)
        else:
            return self._unroll(x, state, reset, idx)

